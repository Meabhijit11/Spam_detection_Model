{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce776e9",
   "metadata": {},
   "source": [
    "# Spam detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b8088",
   "metadata": {},
   "source": [
    "Spam detection is one of the major applications of Machine Learning in the interwebs today. Pretty much all of the major email service providers have spam detection systems built in and automatically classify such mail as 'Junk Mail'.\n",
    "\n",
    "In this project we will be using the Naive Bayes algorithm to create a model that can classify dataset SMS messages as spam or not spam, based on the training we give to the model. \n",
    "\n",
    "It is important to have some level of monitoring as to what a spammy text message might look like. \n",
    "\n",
    "Usually they have words like 'free', 'win', 'winner', 'cash', 'prize' and the like in them as these texts are designed to catch your eye and in some sense tempt you to open them. \n",
    "\n",
    "Also, spam messages tend to have words written in all capitals and also tend to use a lot of exclamation marks. \n",
    "\n",
    "To the recipient, it is usually pretty straightforward to identify a spam text and our objective here is to train a model to do that for us!\n",
    "\n",
    "Being able to identify spam messages is a binary classification problem as messages are classified as either 'Spam' or 'Not Spam' and nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f817a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start with importing necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b593c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data', names = ['label', 'sms_message'])\n",
    "\n",
    "# Output printing out first 5 columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d65b06e",
   "metadata": {},
   "source": [
    "### Here ham = Not Spam & Spam = Is Spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7d1dddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">sms_message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sms_message                                                            \\\n",
       "            count unique                                                top   \n",
       "label                                                                         \n",
       "ham          4825   4516                             Sorry, I'll call later   \n",
       "spam          747    653  Please call our customer service representativ...   \n",
       "\n",
       "            \n",
       "      freq  \n",
       "label       \n",
       "ham     30  \n",
       "spam     4  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0446cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df, x='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3e27d",
   "metadata": {},
   "source": [
    "Distribution plot for \"ham\" & \"spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c070716",
   "metadata": {},
   "source": [
    "### Our approach:\n",
    "\n",
    "1. Clean and Normalize text\n",
    "2. Convert text into vectors (using bag of words model) that machine learning models can understand\n",
    "3. Train and test Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99e442",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Now that we have a basic understanding of what our dataset looks like, lets convert our labels to binary variables, 0 to represent 'ham'(i.e. not spam) and 1 to represent 'spam' for ease of computation.\n",
    "\n",
    "Why we need to do this because, Scikit-learn only deals with numerical values and hence if we were to leave our label values as strings, scikit-learn would do the conversion internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddf9a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = {'ham':0, 'spam':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61012619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4436154c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045c21d",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "What we have here in our data set is a large collection of text data (5,572 rows of data). \n",
    "\n",
    "Most ML algorithms rely on numerical data to be fed into them as input, and email/sms messages are usually text heavy.\n",
    "\n",
    "Here we'd like to introduce the Bag of Words(BoW) concept which is a term used to specify the problems that have a 'bag of words' or a collection of text data that needs to be worked with. \n",
    "\n",
    "The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. \n",
    "\n",
    "It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
    "\n",
    "Using a process which we will go through now, we can covert a collection of documents to a matrix, with each document being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrence of each word or token in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da94e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f10b924",
   "metadata": {},
   "source": [
    "### Text Pre-processing\n",
    "\n",
    "Our main issue with our data is that it is all in text format (strings). The classification algorithms that we've learned about so far will need some sort of numerical feature vector in order to perform the classification task. One method is the the bag-of-words approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "In this section we'll convert the raw messages (sequence of characters) into vectors (sequences of numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4546f",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization converts continuous stream of words into seprate token for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235df371",
   "metadata": {},
   "source": [
    "### To handle this, we will be using \"sklearns count vectorizer\" method which does the following:\n",
    "\n",
    "* It tokenizes the string(separates the string into individual words) and gives an integer ID to each token.\n",
    "\n",
    "\n",
    "* It counts the occurrence of each of those tokens.\n",
    "\n",
    "\n",
    "* The CountVectorizer method automatically converts all tokenized words to their lower case form so that it does not treat words like 'He' and 'he' differently. It does this using the lowercase parameter which is by default set to True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50371821",
   "metadata": {},
   "source": [
    "## Let's Take an Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8b5ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we will look to create a frequency matrix on a smaller document set to make sure we understand how the \n",
    "document-term matrix generation happens. We have created a sample document set 'documents'.\n",
    "'''\n",
    "documents = ['Hello, how are you!',\n",
    "                'Win money, win from home.',\n",
    "                'Call me now.',\n",
    "                'Hello, Call hello you tomorrow?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70e9f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f5098",
   "metadata": {},
   "source": [
    "Fit your document dataset to the CountVectorizer object you have created using fit(), and get the list of words which have been categorized as features using the get_feature_names() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ea4d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meabh\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'call',\n",
       " 'from',\n",
       " 'hello',\n",
       " 'home',\n",
       " 'how',\n",
       " 'me',\n",
       " 'money',\n",
       " 'now',\n",
       " 'tomorrow',\n",
       " 'win',\n",
       " 'you']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.fit(documents)\n",
    "count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e4ad6",
   "metadata": {},
   "source": [
    "Now we will Create a matrix with the rows being each of the 4 documents, and the columns being each word. The corresponding (row, column) value is the frequency of occurrence of that word(in the column) in a particular document(in the row). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0fd9ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_array = count_vector.transform(documents).toarray()\n",
    "doc_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25819474",
   "metadata": {},
   "source": [
    "Now we have a clean representation of the documents in terms of the frequency distribution of the words in them. To make it easier to understand our next step is to convert this array into a dataframe and name the columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8f34227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>call</th>\n",
       "      <th>from</th>\n",
       "      <th>hello</th>\n",
       "      <th>home</th>\n",
       "      <th>how</th>\n",
       "      <th>me</th>\n",
       "      <th>money</th>\n",
       "      <th>now</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>win</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
       "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
       "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
       "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
       "3    0     1     0      2     0    0   0      0    0         1    0    1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(doc_array, columns = count_vector.get_feature_names())\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482c69f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9c98844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "# USE from sklearn.model_selection import train_test_split to avoid seeing deprecation warning.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf96c8",
   "metadata": {},
   "source": [
    "### Applying Bag of Words processing to our dataset.\n",
    "\n",
    "Now that we have split the data, our next objective is to apply Bag of words and convert our data into the desired matrix format. To do this we will be using CountVectorizer(). \n",
    "\n",
    "There are two steps to consider here:\n",
    "\n",
    "* Firstly, we have to fit our training data (X_train) into CountVectorizer() and return the matrix.\n",
    "\n",
    "* Secondly, we have to transform our testing data (X_test) to return the matrix.\n",
    "\n",
    "Note that X_train is our training data for the 'sms_message' column in our dataset and we will be using this to train our model.\n",
    "\n",
    "X_test is our testing data for the 'sms_message' column and this is the data we will be using(after transformation to a matrix) to make predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de43352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4a9fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d848b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "064b5a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "703be1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9885139985642498\n",
      "Precision score:  0.9405405405405406\n",
      "Recall score:  0.9720670391061452\n",
      "F1 score:  0.9560439560439562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(predictions, y_test)))\n",
    "print('Precision score: ', format(precision_score(predictions, y_test)))\n",
    "print('Recall score: ', format(recall_score(predictions, y_test)))\n",
    "print('F1 score: ', format(f1_score(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff409c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "One of the major advantages that Naive Bayes has over other classification algorithms is its ability to handle an extremely large number of features. \n",
    "\n",
    "In our case, each word is treated as a feature and there are thousands of different words. Also, it performs well even with the presence of irrelevant features and is relatively unaffected by them. \n",
    "\n",
    "Another important advantage is that its model training and prediction times are very fast for the amount of data it can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66107d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
